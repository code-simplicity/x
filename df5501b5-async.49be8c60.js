(("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]=("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]||[]).push([["df5501b5"],{"6dbc0115":function(e,n,t){"use strict";t.d(n,"__esModule",{value:!0}),t.d(n,"texts",{enumerable:!0,get:function(){return s;}}),t("3ae5d1e9");let s=[{value:"This guide introduces how to integrate Qwen model services into applications built with Ant Design X.",paraId:0},{value:'Qwen\'s model inference service supports "OpenAI compatible mode". See official documentation: ',paraId:1},{value:"Alibaba Cloud - Qwen",paraId:1},{value:"How to get baseURL - ",paraId:2,tocIndex:0},{value:"https://help.aliyun.com/zh/model-studio/getting-started/what-is-model-studio",paraId:2,tocIndex:0},{value:"How to get API Key - ",paraId:2,tocIndex:0},{value:"https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key",paraId:2,tocIndex:0},{value:"Model list - ",paraId:2,tocIndex:0},{value:"https://help.aliyun.com/zh/model-studio/getting-started/models",paraId:2,tocIndex:0},{value:"It refers to model inference services that keep the API design and usage consistent with OpenAI. This means developers can use the same code and methods as calling OpenAI models to call these compatible services, reducing integration development costs.",paraId:3,tocIndex:1},{value:"Using URL to integrate Model is a basic capability provided by X SDK. For details, see ",paraId:4,tocIndex:2},{value:"X SDK",paraId:5,tocIndex:2},{value:".",paraId:4,tocIndex:2},{value:"Note: \u{1F525} ",paraId:6,tocIndex:5},{value:"dangerouslyAllowBrowser",paraId:6,tocIndex:5},{value:" has security risks. See the official openai-node ",paraId:6,tocIndex:5},{value:"documentation",paraId:6,tocIndex:5},{value:" for details.",paraId:6,tocIndex:5},{value:"import { Bubble, BubbleListProps, Sender } from '@ant-design/x';\nimport {\n  AbstractXRequestClass,\n  OpenAIChatProvider,\n  SSEFields,\n  useXChat,\n  XModelMessage,\n  XModelParams,\n  XRequestOptions,\n} from '@ant-design/x-sdk';\nimport { Flex } from 'antd';\nimport OpenAI from 'openai';\nimport React, { useState } from 'react';\n\ntype OutputType = Partial<Record<SSEFields, any>>;\ntype InputType = XModelParams;\n\nclass OpenAiRequest<\n  Input extends InputType = InputType,\n  Output extends OutputType = OutputType,\n> extends AbstractXRequestClass<Input, Output> {\n  client: any;\n  stream: OpenAI | undefined;\n\n  _isTimeout = false;\n  _isStreamTimeout = false;\n  _isRequesting = false;\n\n  constructor(baseURL: string, options: XRequestOptions<Input, Output>) {\n    super(baseURL, options);\n    this.client = new OpenAI({\n      baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',\n      apiKey: 'OPENAI_API_KEY',\n      dangerouslyAllowBrowser: true,\n    });\n  }\n  get asyncHandler(): Promise<any> {\n    return Promise.resolve();\n  }\n  get isTimeout(): boolean {\n    return this._isTimeout;\n  }\n  get isStreamTimeout(): boolean {\n    return this._isStreamTimeout;\n  }\n  get isRequesting(): boolean {\n    return this._isRequesting;\n  }\n  get manual(): boolean {\n    return true;\n  }\n  async run(input: Input): Promise<void> {\n    const { callbacks } = this.options;\n    try {\n      await this.client.responses.create({\n        model: 'qwen-plus',\n        messages: input?.messages || [],\n        stream: true,\n      });\n\n      // Please implement stream data update logic based on response\n    } catch (error: any) {\n      callbacks?.onError(error);\n    }\n  }\n  abort(): void {\n    // Please implement abort based on OpenAI\n  }\n}\n\nconst provider = new OpenAIChatProvider<XModelMessage, InputType, OutputType>({\n  request: new OpenAiRequest('OPENAI', {}),\n});\n\nconst Demo: React.FC = () => {\n  const [content, setContent] = useState('');\n  const { onRequest, messages, isRequesting, abort } = useXChat({\n    provider,\n    requestPlaceholder: () => {\n      return {\n        content: 'loading...',\n        role: 'assistant',\n      };\n    },\n    requestFallback: (_, { error }) => {\n      if (error.name === 'AbortError') {\n        return {\n          content: 'Request is aborted',\n          role: 'assistant',\n        };\n      }\n      return {\n        content: error?.toString(),\n        role: 'assistant',\n      };\n    },\n  });\n\n  const items = messages.map(({ message, id }) => ({\n    key: id,\n    ...message,\n  }));\n\n  const role: BubbleListProps['role'] = {\n    assistant: {\n      placement: 'start',\n    },\n    user: { placement: 'end' },\n  };\n\n  return (\n    <Flex\n      vertical\n      justify=\"space-between\"\n      style={{\n        height: 400,\n        padding: 16,\n      }}\n    >\n      <Bubble.List role={role} items={items} />\n      <Sender\n        value={content}\n        onChange={setContent}\n        loading={isRequesting}\n        onCancel={abort}\n        onSubmit={(val) => {\n          onRequest({\n            messages: [{ role: 'user', content: val }],\n          });\n          setContent('');\n        }}\n      />\n    </Flex>\n  );\n};\n\nexport default Demo;\n",paraId:7,tocIndex:5}];},df5501b5:function(e,n,t){"use strict";t.d(n,"__esModule",{value:!0}),t.d(n,"default",{enumerable:!0,get:function(){return d;}});var s=t("777fffbe"),r=t("dcc18016"),a=s._(t("9e95e7ac")),o=s._(t("80a4173a")),i=t("2ccdbe5e"),l=s._(t("d64cba85")),c=t("896e0d47"),p=t("6dbc0115"),d=function(){return(0,r.jsx)(i.DumiPage,{children:(0,r.jsx)(c.Suspense,{fallback:(0,r.jsx)(l.default,{}),children:(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)("div",{className:"markdown",children:[(0,r.jsx)("p",{children:p.texts[0].value}),(0,r.jsxs)("p",{children:[p.texts[1].value,(0,r.jsx)(o.default,{href:"https://help.aliyun.com/zh/model-studio/developer-reference/compatibility-of-openai-with-dashscope",sourceType:"a",children:p.texts[2].value})]}),(0,r.jsxs)("h3",{id:"related-parameter-acquisition",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#related-parameter-acquisition",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Related Parameter Acquisition"]}),(0,r.jsxs)("ul",{children:[(0,r.jsxs)("li",{children:[p.texts[3].value,(0,r.jsx)(o.default,{href:"https://help.aliyun.com/zh/model-studio/getting-started/what-is-model-studio",sourceType:"a",children:p.texts[4].value})]}),(0,r.jsxs)("li",{children:[p.texts[5].value,(0,r.jsx)(o.default,{href:"https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key",sourceType:"a",children:p.texts[6].value})]}),(0,r.jsxs)("li",{children:[p.texts[7].value,(0,r.jsx)(o.default,{href:"https://help.aliyun.com/zh/model-studio/getting-started/models",sourceType:"a",children:p.texts[8].value})]})]}),(0,r.jsxs)("h3",{id:"what-is-openai-compatible-mode",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#what-is-openai-compatible-mode",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),'What is "OpenAI compatible mode"?']}),(0,r.jsx)("p",{children:p.texts[9].value}),(0,r.jsxs)("h2",{id:"integrate-with-x-sdk",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#integrate-with-x-sdk",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Integrate with X SDK"]}),(0,r.jsxs)("p",{children:[p.texts[10].value,(0,r.jsx)(o.default,{to:"/x-sdks/introduce",sourceType:"Link",children:p.texts[11].value}),p.texts[12].value]}),(0,r.jsxs)("h3",{id:"example",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#example",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Example"]})]}),(0,r.jsx)(i.DumiDemo,{demo:{id:"docs-react-model-use-qwen-demo-qwen-sdk"},previewerProps:{title:"Integrate with X SDK",filename:"docs/react/demo/qwen-sdk.tsx",pkgDependencyList:{"tbox-nodejs-sdk":"^0.0.13",openai:"^5.20.0","@antv/gpt-vis":"^0.4.1","@codesandbox/sandpack-react":"^2.19.8","@emotion/react":"^11.13.5","@emotion/server":"^11.11.0","@happy-dom/jest-environment":"^18.0.1","@ianvs/prettier-plugin-sort-imports":"^4.3.1","@microflash/rehype-figure":"^2.1.1","@npmcli/run-script":"^9.0.1","@octokit/rest":"^21.0.2","@prettier/sync":"^0.6.1","@qixian.cs/github-contributors-list":"^2.0.2","@rc-component/father-plugin":"^2.0.4","@rc-component/np":"^1.0.3","@rc-component/trigger":"^2.2.3","@stackblitz/sdk":"^1.11.0","@testing-library/dom":"^10.4.0","@testing-library/jest-dom":"^6.5.0","@testing-library/react":"^16.0.1","@testing-library/user-event":"^14.5.2","@types/adm-zip":"^0.5.5","@types/ali-oss":"^6.16.11","@types/cli-progress":"^3.11.6","@types/fs-extra":"^11.0.4","@types/gtag.js":"^0.0.20","@types/http-server":"^0.12.4","@types/inquirer":"^9.0.7","@types/isomorphic-fetch":"^0.0.39","@types/jest":"^30.0.0","@types/jest-axe":"^3.5.9","@types/jest-environment-puppeteer":"^5.0.6","@types/jest-image-snapshot":"^6.4.0","@types/jquery":"^3.5.30","@types/jsdom":"^27.0.0","@types/lodash":"^4.17.7","@types/minimist":"^1.2.5","@types/node":"^24.0.3","@types/ora":"^3.2.0","@types/pixelmatch":"^5.2.6","@types/pngjs":"^6.0.5","@types/prismjs":"^1.26.4","@types/progress":"^2.0.7","@types/qs":"^6.9.16","@types/react":"^19.0.2","@types/react-copy-to-clipboard":"^5.0.7","@types/react-dom":"^19.0.2","@types/react-highlight-words":"^0.20.0","@types/react-resizable":"^3.0.8","@types/semver":"^7.5.8","@types/spinnies":"^0.5.3","@types/tar":"^6.1.13","@types/throttle-debounce":"^5.0.2","@types/warning":"^3.0.3","@umijs/fabric":"^4.0.1","adm-zip":"^0.5.16","ali-oss":"^6.21.0",antd:"^6.0.0","antd-style":"^4.0.0-alpha.1","antd-token-previewer":"^3.0.0",axios:"^1.7.7",browserslist:"^4.23.3","browserslist-to-esbuild":"^2.1.1",chalk:"^5.4.1",cheerio:"^1.0.0","cli-progress":"^3.12.0","copy-to-clipboard":"^3.3.3","cross-env":"^7.0.3","cross-fetch":"^4.0.0",crypto:"^1.0.1",dayjs:"^1.11.13",dumi:"~2.4.21","dumi-plugin-color-chunk":"^2.1.0","esbuild-loader":"^4.2.2","fast-glob":"^3.3.2","fetch-jsonp":"^1.3.0","fs-extra":"^11.2.0",glob:"^11.0.0","happy-dom":"^20.0.10",html2sketch:"^1.0.2","http-server":"^14.1.1","identity-obj-proxy":"^3.0.0",immer:"^10.1.1",inquirer:"^12.1.0","is-ci":"^4.1.0","isomorphic-fetch":"^3.0.0",jest:"^30.2.0","jest-axe":"^10.0.0","jest-canvas-mock":"^2.5.2","jest-environment-node":"^30.0.0","jest-image-snapshot":"^6.5.1","jest-puppeteer":"^11.0.0",jquery:"^3.7.1",jsdom:"^26.0.0","jsonml-to-react-element":"^1.1.11","jsonml.js":"^0.1.0",lodash:"^4.17.21","lottie-web":"^5.12.2","lunar-typescript":"^1.7.5","lz-string":"^1.5.0",minimist:"^1.2.8",mockdate:"^3.0.5","node-fetch":"^3.3.2","node-notifier":"^10.0.1",open:"^10.1.0",ora:"^8.1.0",pixelmatch:"^7.1.0",pngjs:"^7.0.0","prettier-plugin-jsdoc":"^1.3.0","pretty-format":"^30.0.0",prismjs:"^1.29.0",puppeteer:"^24.0.0",qs:"^6.13.0","rc-drawer":"^8.0.0","rc-footer":"^0.6.8","rc-resize-observer":"^1.4.0","rc-virtual-list":"^3.14.5",react:"^19.0.0","react-copy-to-clipboard":"^5.1.0","react-dom":"^19.0.0","react-highlight-words":"^0.20.0","react-infinite-scroll-component":"^6.1.0","react-intersection-observer":"^10.0.0","react-intl":"^7.1.11","react-resizable":"^3.0.5","react-router-dom":"^7.0.1","react-sticky-box":"^2.0.5","regenerator-runtime":"^0.14.1","rehype-stringify":"^10.0.0",remark:"^15.0.1","remark-cli":"^12.0.1","remark-gfm":"^4.0.0","remark-lint":"^10.0.0","remark-lint-no-undefined-references":"^5.0.0","remark-preset-lint-recommended":"^7.0.0","remark-rehype":"^11.1.0","scroll-into-view-if-needed":"^3.1.0",semver:"^7.6.3",sharp:"^0.33.5","simple-git":"^3.26.0",spinnies:"^0.5.1",tar:"^7.4.3",tsx:"^4.19.1",typedoc:"^0.28.0",typescript:"~5.8.2","vanilla-jsoneditor":"^3.0.0","web-streams-polyfill":"^4.0.0",webpack:"^5.94.0","webpack-bundle-analyzer":"^5.0.1","@ant-design/colors":"^8.0.0","@ant-design/cssinjs":"^2.0.0","@ant-design/cssinjs-utils":"^2.0.0","@ant-design/fast-color":"^3.0.0","@ant-design/icons":"^6.0.0","@babel/runtime":"^7.25.6",classnames:"^2.5.1","rc-motion":"^2.9.2","rc-util":"^5.43.0"},pkgPeerDependencies:{antd:"^6.0.0",react:">=18.0.0","react-dom":">=18.0.0"},jsx:"import { SyncOutlined } from '@ant-design/icons';\nimport { Bubble, Sender } from '@ant-design/x';\nimport XMarkdown from '@ant-design/x-markdown';\nimport { OpenAIChatProvider, useXChat, XRequest } from '@ant-design/x-sdk';\nimport { Button, Flex, Tooltip } from 'antd';\nimport React from 'react';\n/**\n * \u{1F514} Please replace the BASE_URL, PATH, MODEL, API_KEY with your own values.\n */\nconst BASE_URL = 'https://api.x.ant.design/api/llm_cloudflare_qwq-32b';\n/**\n * \u{1F514} The MODEL is fixed in the current request, please replace it with your BASE_UR and MODEL\n */\nconst MODEL = 'qwq-32b';\nconst role = {\n  assistant: {\n    placement: 'start',\n    contentRender(content) {\n      // Double '\\n' in a mark will causes markdown parse as a new paragraph, so we need to replace it with a single '\\n'\n      const newContent = content.replace('/\\n\\n/g', '<br/><br/>');\n      return <XMarkdown content={newContent} />;\n    },\n  },\n  user: {\n    placement: 'end',\n  },\n};\nconst App = () => {\n  const [content, setContent] = React.useState('');\n  const [provider] = React.useState(\n    new OpenAIChatProvider({\n      request: XRequest(BASE_URL, {\n        manual: true,\n        params: {\n          model: MODEL,\n          stream: true,\n        },\n      }),\n    }),\n  );\n  // Chat messages\n  const { onRequest, messages, isRequesting, abort, onReload } = useXChat({\n    provider,\n    requestFallback: (_, { error }) => {\n      if (error.name === 'AbortError') {\n        return {\n          content: 'Request is aborted',\n          role: 'assistant',\n        };\n      }\n      return {\n        content: 'Request failed, please try again!',\n        role: 'assistant',\n      };\n    },\n    requestPlaceholder: () => {\n      return {\n        content: 'Please wait...',\n        role: 'assistant',\n      };\n    },\n  });\n  return (\n    <Flex vertical gap=\"middle\">\n      <Bubble.List\n        role={role}\n        style={{ maxHeight: 300 }}\n        items={messages.map(({ id, message, status }) => ({\n          key: id,\n          role: message.role,\n          status: status,\n          loading: status === 'loading',\n          content: message.content,\n          components:\n            message.role === 'assistant'\n              ? {\n                  footer: (\n                    <Tooltip title=\"Retry\">\n                      <Button\n                        size=\"small\"\n                        type=\"text\"\n                        icon={<SyncOutlined />}\n                        style={{ marginInlineEnd: 'auto' }}\n                        onClick={() =>\n                          onReload(id, {\n                            userAction: 'retry',\n                          })\n                        }\n                      />\n                    </Tooltip>\n                  ),\n                }\n              : {},\n        }))}\n      />\n      <Sender\n        loading={isRequesting}\n        value={content}\n        onCancel={() => {\n          abort();\n        }}\n        onChange={setContent}\n        onSubmit={nextContent => {\n          onRequest({\n            messages: [\n              {\n                role: 'user',\n                content: nextContent,\n              },\n            ],\n          });\n          setContent('');\n        }}\n      />\n    </Flex>\n  );\n};\nexport default App;\n"}}),(0,r.jsxs)("div",{className:"markdown",children:[(0,r.jsxs)("h2",{id:"use-openai-node-for-compatible-calls",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#use-openai-node-for-compatible-calls",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Use openai-node for compatible calls"]}),(0,r.jsx)("blockquote",{children:(0,r.jsxs)("p",{children:[p.texts[13].value,(0,r.jsx)("code",{children:p.texts[14].value}),p.texts[15].value,(0,r.jsx)(o.default,{href:"https://github.com/openai/openai-node?tab=readme-ov-file#requirements",sourceType:"a",children:p.texts[16].value}),p.texts[17].value]})}),(0,r.jsx)(a.default,{lang:"tsx",children:p.texts[18].value}),(0,r.jsxs)("h3",{id:"example-1",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#example-1",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Example"]})]}),(0,r.jsx)(i.DumiDemo,{demo:{id:"docs-react-model-use-qwen-demo-qwen"},previewerProps:{title:"Integrate openai with qwen",description:"<p>This example only shows the logic reference for integrating openai with X SDK. Model data is not processed, please fill in the correct apiKey for data debugging.</p>",filename:"docs/react/demo/qwen.tsx",pkgDependencyList:{"tbox-nodejs-sdk":"^0.0.13",openai:"^5.20.0","@antv/gpt-vis":"^0.4.1","@codesandbox/sandpack-react":"^2.19.8","@emotion/react":"^11.13.5","@emotion/server":"^11.11.0","@happy-dom/jest-environment":"^18.0.1","@ianvs/prettier-plugin-sort-imports":"^4.3.1","@microflash/rehype-figure":"^2.1.1","@npmcli/run-script":"^9.0.1","@octokit/rest":"^21.0.2","@prettier/sync":"^0.6.1","@qixian.cs/github-contributors-list":"^2.0.2","@rc-component/father-plugin":"^2.0.4","@rc-component/np":"^1.0.3","@rc-component/trigger":"^2.2.3","@stackblitz/sdk":"^1.11.0","@testing-library/dom":"^10.4.0","@testing-library/jest-dom":"^6.5.0","@testing-library/react":"^16.0.1","@testing-library/user-event":"^14.5.2","@types/adm-zip":"^0.5.5","@types/ali-oss":"^6.16.11","@types/cli-progress":"^3.11.6","@types/fs-extra":"^11.0.4","@types/gtag.js":"^0.0.20","@types/http-server":"^0.12.4","@types/inquirer":"^9.0.7","@types/isomorphic-fetch":"^0.0.39","@types/jest":"^30.0.0","@types/jest-axe":"^3.5.9","@types/jest-environment-puppeteer":"^5.0.6","@types/jest-image-snapshot":"^6.4.0","@types/jquery":"^3.5.30","@types/jsdom":"^27.0.0","@types/lodash":"^4.17.7","@types/minimist":"^1.2.5","@types/node":"^24.0.3","@types/ora":"^3.2.0","@types/pixelmatch":"^5.2.6","@types/pngjs":"^6.0.5","@types/prismjs":"^1.26.4","@types/progress":"^2.0.7","@types/qs":"^6.9.16","@types/react":"^19.0.2","@types/react-copy-to-clipboard":"^5.0.7","@types/react-dom":"^19.0.2","@types/react-highlight-words":"^0.20.0","@types/react-resizable":"^3.0.8","@types/semver":"^7.5.8","@types/spinnies":"^0.5.3","@types/tar":"^6.1.13","@types/throttle-debounce":"^5.0.2","@types/warning":"^3.0.3","@umijs/fabric":"^4.0.1","adm-zip":"^0.5.16","ali-oss":"^6.21.0",antd:"^6.0.0","antd-style":"^4.0.0-alpha.1","antd-token-previewer":"^3.0.0",axios:"^1.7.7",browserslist:"^4.23.3","browserslist-to-esbuild":"^2.1.1",chalk:"^5.4.1",cheerio:"^1.0.0","cli-progress":"^3.12.0","copy-to-clipboard":"^3.3.3","cross-env":"^7.0.3","cross-fetch":"^4.0.0",crypto:"^1.0.1",dayjs:"^1.11.13",dumi:"~2.4.21","dumi-plugin-color-chunk":"^2.1.0","esbuild-loader":"^4.2.2","fast-glob":"^3.3.2","fetch-jsonp":"^1.3.0","fs-extra":"^11.2.0",glob:"^11.0.0","happy-dom":"^20.0.10",html2sketch:"^1.0.2","http-server":"^14.1.1","identity-obj-proxy":"^3.0.0",immer:"^10.1.1",inquirer:"^12.1.0","is-ci":"^4.1.0","isomorphic-fetch":"^3.0.0",jest:"^30.2.0","jest-axe":"^10.0.0","jest-canvas-mock":"^2.5.2","jest-environment-node":"^30.0.0","jest-image-snapshot":"^6.5.1","jest-puppeteer":"^11.0.0",jquery:"^3.7.1",jsdom:"^26.0.0","jsonml-to-react-element":"^1.1.11","jsonml.js":"^0.1.0",lodash:"^4.17.21","lottie-web":"^5.12.2","lunar-typescript":"^1.7.5","lz-string":"^1.5.0",minimist:"^1.2.8",mockdate:"^3.0.5","node-fetch":"^3.3.2","node-notifier":"^10.0.1",open:"^10.1.0",ora:"^8.1.0",pixelmatch:"^7.1.0",pngjs:"^7.0.0","prettier-plugin-jsdoc":"^1.3.0","pretty-format":"^30.0.0",prismjs:"^1.29.0",puppeteer:"^24.0.0",qs:"^6.13.0","rc-drawer":"^8.0.0","rc-footer":"^0.6.8","rc-resize-observer":"^1.4.0","rc-virtual-list":"^3.14.5",react:"^19.0.0","react-copy-to-clipboard":"^5.1.0","react-dom":"^19.0.0","react-highlight-words":"^0.20.0","react-infinite-scroll-component":"^6.1.0","react-intersection-observer":"^10.0.0","react-intl":"^7.1.11","react-resizable":"^3.0.5","react-router-dom":"^7.0.1","react-sticky-box":"^2.0.5","regenerator-runtime":"^0.14.1","rehype-stringify":"^10.0.0",remark:"^15.0.1","remark-cli":"^12.0.1","remark-gfm":"^4.0.0","remark-lint":"^10.0.0","remark-lint-no-undefined-references":"^5.0.0","remark-preset-lint-recommended":"^7.0.0","remark-rehype":"^11.1.0","scroll-into-view-if-needed":"^3.1.0",semver:"^7.6.3",sharp:"^0.33.5","simple-git":"^3.26.0",spinnies:"^0.5.1",tar:"^7.4.3",tsx:"^4.19.1",typedoc:"^0.28.0",typescript:"~5.8.2","vanilla-jsoneditor":"^3.0.0","web-streams-polyfill":"^4.0.0",webpack:"^5.94.0","webpack-bundle-analyzer":"^5.0.1","@ant-design/colors":"^8.0.0","@ant-design/cssinjs":"^2.0.0","@ant-design/cssinjs-utils":"^2.0.0","@ant-design/fast-color":"^3.0.0","@ant-design/icons":"^6.0.0","@babel/runtime":"^7.25.6",classnames:"^2.5.1","rc-motion":"^2.9.2","rc-util":"^5.43.0"},pkgPeerDependencies:{antd:"^6.0.0",react:">=18.0.0","react-dom":">=18.0.0"},jsx:"var __awaiter =\n  (this && this.__awaiter) ||\n  function (thisArg, _arguments, P, generator) {\n    function adopt(value) {\n      return value instanceof P\n        ? value\n        : new P(function (resolve) {\n            resolve(value);\n          });\n    }\n    return new (P || (P = Promise))(function (resolve, reject) {\n      function fulfilled(value) {\n        try {\n          step(generator.next(value));\n        } catch (e) {\n          reject(e);\n        }\n      }\n      function rejected(value) {\n        try {\n          step(generator['throw'](value));\n        } catch (e) {\n          reject(e);\n        }\n      }\n      function step(result) {\n        result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n      }\n      step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n  };\nimport { Bubble, Sender } from '@ant-design/x';\nimport { AbstractXRequestClass, OpenAIChatProvider, useXChat } from '@ant-design/x-sdk';\nimport { Flex } from 'antd';\nimport OpenAI from 'openai';\nimport React, { useState } from 'react';\nclass OpenAiRequest extends AbstractXRequestClass {\n  constructor(baseURL, options) {\n    super(baseURL, options);\n    this._isTimeout = false;\n    this._isStreamTimeout = false;\n    this._isRequesting = false;\n    this.client = new OpenAI({\n      baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',\n      apiKey: 'OPENAI_API_KEY',\n      dangerouslyAllowBrowser: true,\n    });\n  }\n  get asyncHandler() {\n    return Promise.resolve();\n  }\n  get isTimeout() {\n    return this._isTimeout;\n  }\n  get isStreamTimeout() {\n    return this._isStreamTimeout;\n  }\n  get isRequesting() {\n    return this._isRequesting;\n  }\n  get manual() {\n    return true;\n  }\n  run(input) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const { callbacks } = this.options;\n      try {\n        yield this.client.responses.create({\n          model: 'qwen-plus',\n          messages: (input === null || input === void 0 ? void 0 : input.messages) || [],\n          stream: true,\n        });\n        // \u8BF7\u57FA\u4E8E response \u5B9E\u73B0 \u6D41\u6570\u636E\u66F4\u65B0\u903B\u8F91\n        // Please implement stream data update logic based on response\n      } catch (error) {\n        callbacks === null || callbacks === void 0 ? void 0 : callbacks.onError(error);\n      }\n    });\n  }\n  abort() {\n    // \u8BF7\u57FA\u4E8Eopenai \u5B9E\u73B0 abort\n    // Please implement abort based on OpenAI\n  }\n}\nconst provider = new OpenAIChatProvider({\n  request: new OpenAiRequest('OPENAI', {}),\n});\nconst Demo = () => {\n  const [content, setContent] = useState('');\n  const { onRequest, messages, isRequesting, abort } = useXChat({\n    provider,\n    requestPlaceholder: () => {\n      return {\n        content: 'loading...',\n        role: 'assistant',\n      };\n    },\n    requestFallback: (_, { error }) => {\n      if (error.name === 'AbortError') {\n        return {\n          content: 'Request is aborted',\n          role: 'assistant',\n        };\n      }\n      return {\n        content: error === null || error === void 0 ? void 0 : error.toString(),\n        role: 'assistant',\n      };\n    },\n  });\n  const items = messages.map(({ message, id }) => Object.assign({ key: id }, message));\n  const role = {\n    assistant: {\n      placement: 'start',\n    },\n    user: { placement: 'end' },\n  };\n  return (\n    <Flex\n      vertical\n      gap={16}\n      justify=\"space-between\"\n      style={{\n        height: 400,\n        padding: 16,\n      }}\n    >\n      <Bubble.List role={role} items={items} />\n      <Sender\n        value={content}\n        onChange={setContent}\n        loading={isRequesting}\n        onCancel={abort}\n        onSubmit={val => {\n          onRequest({\n            messages: [{ role: 'user', content: val }],\n          });\n          setContent('');\n        }}\n      />\n    </Flex>\n  );\n};\nexport default Demo;\n"}})]})})});};}}]);
//# sourceMappingURL=df5501b5-async.49be8c60.js.map