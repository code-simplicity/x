(("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]=("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]||[]).push([["a8c7c47b"],{a8c7c47b:function(n,e,t){"use strict";t.d(e,"__esModule",{value:!0}),t.d(e,"texts",{enumerable:!0,get:function(){return a;}}),t("9efcd785");let a=[{value:"\u8FD9\u7BC7\u6307\u5357\u5C06\u4ECB\u7ECD\u5982\u4F55\u5728\u4F7F\u7528 Ant Design X \u642D\u5EFA\u7684\u5E94\u7528\u4E2D\u63A5\u5165 OpenAI \u63D0\u4F9B\u7684\u6A21\u578B\u670D\u52A1\uFF0C\u8BE6\u60C5\u8BF7\u67E5\u770B",paraId:0},{value:"X SDK",paraId:1},{value:"\u3002",paraId:0},{value:"\u4F7F\u7528URL\u63A5\u5165\u6A21\u578B\u662F X SDK\u63D0\u4F9B\u7684\u57FA\u7840\u80FD\u529B\uFF0C\u8BE6\u60C5\u8BF7\u67E5\u770B",paraId:2,tocIndex:0},{value:"X SDK",paraId:3,tocIndex:0},{value:"\u3002",paraId:2,tocIndex:0},{value:"\u901A\u5E38\u60C5\u51B5 openai-node \u7528\u4E8E node \u73AF\u5883\uFF0C\u5982\u679C\u5728\u6D4F\u89C8\u5668\u73AF\u5883\u4F7F\u7528\uFF0C\u9700\u8981\u5F00\u542F ",paraId:4,tocIndex:3},{value:"dangerouslyAllowBrowser",paraId:4,tocIndex:3},{value:"\u3002",paraId:4,tocIndex:3},{value:"\u6CE8\u610F: ",paraId:5,tocIndex:3},{value:"dangerouslyAllowBrowser",paraId:5,tocIndex:3},{value:" \u5B58\u5728\u5B89\u5168\u98CE\u9669\uFF0C\u5BF9\u6B64 openai-node \u7684\u5B98\u65B9\u6587\u6863\u6709\u8BE6\u7EC6\u7684",paraId:5,tocIndex:3},{value:"\u8BF4\u660E",paraId:5,tocIndex:3},{value:"\u3002",paraId:5,tocIndex:3},{value:"import { Bubble, BubbleListProps, Sender } from '@ant-design/x';\nimport {\n  AbstractXRequestClass,\n  OpenAIChatProvider,\n  SSEFields,\n  useXChat,\n  XModelMessage,\n  XModelParams,\n  XRequestOptions,\n} from '@ant-design/x-sdk';\nimport { Flex } from 'antd';\nimport OpenAI from 'openai';\nimport React, { useState } from 'react';\n\ntype OutputType = Partial<Record<SSEFields, any>>;\ntype InputType = XModelParams;\n\nclass OpenAiRequest<\n  Input extends InputType = InputType,\n  Output extends OutputType = OutputType,\n> extends AbstractXRequestClass<Input, Output> {\n  client: any;\n  stream: OpenAI | undefined;\n\n  _isTimeout = false;\n  _isStreamTimeout = false;\n  _isRequesting = false;\n\n  constructor(baseURL: string, options: XRequestOptions<Input, Output>) {\n    super(baseURL, options);\n    this.client = new OpenAI({\n      apiKey: 'OPENAI_API_KEY',\n      dangerouslyAllowBrowser: true,\n    });\n  }\n  get asyncHandler(): Promise<any> {\n    return Promise.resolve();\n  }\n  get isTimeout(): boolean {\n    return this._isTimeout;\n  }\n  get isStreamTimeout(): boolean {\n    return this._isStreamTimeout;\n  }\n  get isRequesting(): boolean {\n    return this._isRequesting;\n  }\n  get manual(): boolean {\n    return true;\n  }\n  async run(input: Input): Promise<void> {\n    const { callbacks } = this.options;\n    try {\n      await this.client.responses.create({\n        model: 'gpt-4o',\n        input: input?.messages?.[0]?.content || '',\n        stream: true,\n      });\n\n      // \u8BF7\u57FA\u4E8E response \u5B9E\u73B0 \u6D41\u6570\u636E\u66F4\u65B0\u903B\u8F91\n      // Please implement stream data update logic based on response\n    } catch (error: any) {\n      callbacks?.onError(error);\n    }\n  }\n  abort(): void {\n    // \u8BF7\u57FA\u4E8Eopenai \u5B9E\u73B0 abort\n    // Please implement abort based on OpenAI\n  }\n}\n\nconst provider = new OpenAIChatProvider<XModelMessage, InputType, OutputType>({\n  request: new OpenAiRequest('OPENAI', {}),\n});\n\nconst Demo: React.FC = () => {\n  const [content, setContent] = useState('');\n  const { onRequest, messages, requesting, abort } = useXChat({\n    provider,\n    requestPlaceholder: () => {\n      return {\n        content: 'loading...',\n        role: 'assistant',\n      };\n    },\n    requestFallback: (_, { error }) => {\n      if (error.name === 'AbortError') {\n        return {\n          content: 'Request is aborted',\n          role: 'assistant',\n        };\n      }\n      return {\n        content: error?.toString(),\n        role: 'assistant',\n      };\n    },\n  });\n\n  const items = messages.map(({ message, id }) => ({\n    key: id,\n    ...message,\n  }));\n\n  const role: BubbleListProps['role'] = {\n    assistant: {\n      placement: 'start',\n    },\n    user: { placement: 'end' },\n  };\n\n  return (\n    <Flex\n      vertical\n      justify=\"space-between\"\n      style={{\n        height: 400,\n        padding: 16,\n      }}\n    >\n      <Bubble.List role={role} items={items} />\n      <Sender\n        value={content}\n        onChange={setContent}\n        loading={requesting}\n        onCancel={abort}\n        onSubmit={(val) => {\n          onRequest({\n            messages: [{ role: 'user', content: val }],\n          });\n          setContent('');\n        }}\n      />\n    </Flex>\n  );\n};\n\nexport default Demo;\n",paraId:6,tocIndex:3}];}}]);
//# sourceMappingURL=a8c7c47b-async.7eb4cade.js.map