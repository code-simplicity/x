(("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]=("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]||[]).push([["37463553"],{37463553:function(e,n,t){"use strict";t.d(n,"__esModule",{value:!0}),t.d(n,"texts",{enumerable:!0,get:function(){return a;}}),t("9a07a017");let a=[{value:"\u8FD9\u7BC7\u6307\u5357\u5C06\u4ECB\u7ECD\u5982\u4F55\u5728\u4F7F\u7528 Ant Design X \u642D\u5EFA\u7684\u5E94\u7528\u4E2D\u63A5\u5165 Qwen \u63D0\u4F9B\u7684\u6A21\u578B\u670D\u52A1\u3002",paraId:0},{value:"Qwen \u7684\u6A21\u578B\u63A8\u7406\u670D\u52A1\u652F\u6301\u300C\u517C\u5BB9 OpenAI \u6A21\u5F0F\u300D\u3002\u8BE6\u89C1\u5B98\u65B9\u6587\u6863: ",paraId:1},{value:"\u963F\u91CC\u4E91 - \u901A\u4E49\u5343\u95EE",paraId:1},{value:"\u5982\u4F55\u83B7\u53D6 baseURL - ",paraId:2,tocIndex:0},{value:"https://help.aliyun.com/zh/model-studio/getting-started/what-is-model-studio",paraId:2,tocIndex:0},{value:"\u5982\u4F55\u83B7\u53D6 API Key - ",paraId:2,tocIndex:0},{value:"https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key",paraId:2,tocIndex:0},{value:"\u6A21\u578B\u5217\u8868 - ",paraId:2,tocIndex:0},{value:"https://help.aliyun.com/zh/model-studio/getting-started/models",paraId:2,tocIndex:0},{value:"\u662F\u6307\u5728\u63A5\u53E3\u8BBE\u8BA1\u548C\u4F7F\u7528\u65B9\u5F0F\u4E0A\u4E0E OpenAI \u7684 API \u4FDD\u6301\u4E00\u81F4\u7684\u6A21\u578B\u63A8\u7406\u670D\u52A1\u3002",paraId:3,tocIndex:1},{value:"\u8FD9\u610F\u5473\u7740\u5F00\u53D1\u8005\u53EF\u4EE5\u4F7F\u7528\u4E0E\u8C03\u7528 OpenAI \u6A21\u578B\u76F8\u540C\u7684\u4EE3\u7801\u548C\u65B9\u6CD5\uFF0C\u6765\u8C03\u7528\u8FD9\u4E9B\u517C\u5BB9\u670D\u52A1\uFF0C\u4ECE\u800C\u51CF\u5C11\u5F00\u53D1\u63A5\u5165\u6210\u672C\u3002",paraId:4,tocIndex:1},{value:"\u4F7F\u7528URL\u63A5\u5165\u6A21\u578B\u662F X SDK\u63D0\u4F9B\u7684\u57FA\u7840\u80FD\u529B\uFF0C\u8BE6\u60C5\u8BF7\u67E5\u770B",paraId:5,tocIndex:2},{value:"X SDK",paraId:6,tocIndex:2},{value:"\u3002",paraId:5,tocIndex:2},{value:"\u6CE8\u610F: \u{1F525} ",paraId:7,tocIndex:5},{value:"dangerouslyAllowBrowser",paraId:7,tocIndex:5},{value:" \u5B58\u5728\u5B89\u5168\u98CE\u9669\uFF0C\u5BF9\u6B64 openai-node \u7684\u5B98\u65B9\u6587\u6863\u6709\u8BE6\u7EC6\u7684",paraId:7,tocIndex:5},{value:"\u8BF4\u660E",paraId:7,tocIndex:5},{value:"\u3002",paraId:7,tocIndex:5},{value:"import { Bubble, BubbleListProps, Sender } from '@ant-design/x';\nimport {\n  AbstractXRequestClass,\n  OpenAIChatProvider,\n  SSEFields,\n  useXChat,\n  XModelMessage,\n  XModelParams,\n  XRequestOptions,\n} from '@ant-design/x-sdk';\nimport { Flex } from 'antd';\nimport OpenAI from 'openai';\nimport React, { useState } from 'react';\n\ntype OutputType = Partial<Record<SSEFields, any>>;\ntype InputType = XModelParams;\n\nclass OpenAiRequest<\n  Input extends InputType = InputType,\n  Output extends OutputType = OutputType,\n> extends AbstractXRequestClass<Input, Output> {\n  client: any;\n  stream: OpenAI | undefined;\n\n  _isTimeout = false;\n  _isStreamTimeout = false;\n  _isRequesting = false;\n\n  constructor(baseURL: string, options: XRequestOptions<Input, Output>) {\n    super(baseURL, options);\n    this.client = new OpenAI({\n      baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1',\n      apiKey: 'OPENAI_API_KEY',\n      dangerouslyAllowBrowser: true,\n    });\n  }\n  get asyncHandler(): Promise<any> {\n    return Promise.resolve();\n  }\n  get isTimeout(): boolean {\n    return this._isTimeout;\n  }\n  get isStreamTimeout(): boolean {\n    return this._isStreamTimeout;\n  }\n  get isRequesting(): boolean {\n    return this._isRequesting;\n  }\n  get manual(): boolean {\n    return true;\n  }\n  async run(input: Input): Promise<void> {\n    const { callbacks } = this.options;\n    try {\n      await this.client.responses.create({\n        model: 'qwen-plus',\n        messages: input?.messages || [],\n        stream: true,\n      });\n\n      // \u8BF7\u57FA\u4E8E response \u5B9E\u73B0 \u6D41\u6570\u636E\u66F4\u65B0\u903B\u8F91\n      // Please implement stream data update logic based on response\n    } catch (error: any) {\n      callbacks?.onError(error);\n    }\n  }\n  abort(): void {\n    // \u8BF7\u57FA\u4E8Eopenai \u5B9E\u73B0 abort\n    // Please implement abort based on OpenAI\n  }\n}\n\nconst provider = new OpenAIChatProvider<XModelMessage, InputType, OutputType>({\n  request: new OpenAiRequest('OPENAI', {}),\n});\n\nconst Demo: React.FC = () => {\n  const [content, setContent] = useState('');\n  const { onRequest, messages, isRequesting, abort } = useXChat({\n    provider,\n    requestPlaceholder: () => {\n      return {\n        content: 'loading...',\n        role: 'assistant',\n      };\n    },\n    requestFallback: (_, { error }) => {\n      if (error.name === 'AbortError') {\n        return {\n          content: 'Request is aborted',\n          role: 'assistant',\n        };\n      }\n      return {\n        content: error?.toString(),\n        role: 'assistant',\n      };\n    },\n  });\n\n  const items = messages.map(({ message, id }) => ({\n    key: id,\n    ...message,\n  }));\n\n  const role: BubbleListProps['role'] = {\n    assistant: {\n      placement: 'start',\n    },\n    user: { placement: 'end' },\n  };\n\n  return (\n    <Flex\n      vertical\n      justify=\"space-between\"\n      style={{\n        height: 400,\n        padding: 16,\n      }}\n    >\n      <Bubble.List role={role} items={items} />\n      <Sender\n        value={content}\n        onChange={setContent}\n        loading={isRequesting}\n        onCancel={abort}\n        onSubmit={(val) => {\n          onRequest({\n            messages: [{ role: 'user', content: val }],\n          });\n          setContent('');\n        }}\n      />\n    </Flex>\n  );\n};\n\nexport default Demo;\n",paraId:8,tocIndex:5}];}}]);
//# sourceMappingURL=37463553-async.6b391dbf.js.map