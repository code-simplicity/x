{"version":3,"sources":["docs/react/model-use-openai.en-US.md?type=text"],"sourcesContent":["\n  import '/Users/dupeiyi/Project/private/x/packages/x/docs/react/model-use-openai.en-US.md?watch=parent';\n  export const texts = [{\"value\":\"This guide introduces how to integrate OpenAI model services into applications built with Ant Design X. For details, see \",\"paraId\":0},{\"value\":\"X SDK\",\"paraId\":1},{\"value\":\".\",\"paraId\":0},{\"value\":\"Using URL to integrate Model is a basic capability provided by X SDK. For details, see \",\"paraId\":2,\"tocIndex\":0},{\"value\":\"X SDK\",\"paraId\":3,\"tocIndex\":0},{\"value\":\".\",\"paraId\":2,\"tocIndex\":0},{\"value\":\"Usually, openai-node is used in the node environment. If you use it in the browser, you need to enable \",\"paraId\":4,\"tocIndex\":3},{\"value\":\"dangerouslyAllowBrowser\",\"paraId\":4,\"tocIndex\":3},{\"value\":\".\",\"paraId\":4,\"tocIndex\":3},{\"value\":\"Note: \",\"paraId\":5,\"tocIndex\":3},{\"value\":\"dangerouslyAllowBrowser\",\"paraId\":5,\"tocIndex\":3},{\"value\":\" has security risks. See the official openai-node \",\"paraId\":5,\"tocIndex\":3},{\"value\":\"documentation\",\"paraId\":5,\"tocIndex\":3},{\"value\":\" for details.\",\"paraId\":5,\"tocIndex\":3},{\"value\":\"import { Bubble, BubbleListProps, Sender } from '@ant-design/x';\\nimport {\\n  AbstractXRequestClass,\\n  OpenAIChatProvider,\\n  SSEFields,\\n  useXChat,\\n  XModelMessage,\\n  XModelParams,\\n  XRequestOptions,\\n} from '@ant-design/x-sdk';\\nimport { Flex } from 'antd';\\nimport OpenAI from 'openai';\\nimport React, { useState } from 'react';\\n\\ntype OutputType = Partial<Record<SSEFields, any>>;\\ntype InputType = XModelParams;\\n\\nclass OpenAiRequest<\\n  Input extends InputType = InputType,\\n  Output extends OutputType = OutputType,\\n> extends AbstractXRequestClass<Input, Output> {\\n  client: any;\\n  stream: OpenAI | undefined;\\n\\n  _isTimeout = false;\\n  _isStreamTimeout = false;\\n  _isRequesting = false;\\n\\n  constructor(baseURL: string, options: XRequestOptions<Input, Output>) {\\n    super(baseURL, options);\\n    this.client = new OpenAI({\\n      apiKey: 'OPENAI_API_KEY',\\n      dangerouslyAllowBrowser: true,\\n    });\\n  }\\n  get asyncHandler(): Promise<any> {\\n    return Promise.resolve();\\n  }\\n  get isTimeout(): boolean {\\n    return this._isTimeout;\\n  }\\n  get isStreamTimeout(): boolean {\\n    return this._isStreamTimeout;\\n  }\\n  get isRequesting(): boolean {\\n    return this._isRequesting;\\n  }\\n  get manual(): boolean {\\n    return true;\\n  }\\n  async run(input: Input): Promise<void> {\\n    const { callbacks } = this.options;\\n    try {\\n      await this.client.responses.create({\\n        model: 'gpt-4o',\\n        input: input?.messages?.[0]?.content || '',\\n        stream: true,\\n      });\\n\\n      // Please implement stream data update logic based on response\\n    } catch (error: any) {\\n      callbacks?.onError(error);\\n    }\\n  }\\n  abort(): void {\\n    // Please implement abort based on OpenAI\\n  }\\n}\\n\\nconst provider = new OpenAIChatProvider<XModelMessage, InputType, OutputType>({\\n  request: new OpenAiRequest('OPENAI', {}),\\n});\\n\\nconst Demo: React.FC = () => {\\n  const [content, setContent] = useState('');\\n  const { onRequest, messages, requesting, abort } = useXChat({\\n    provider,\\n    requestPlaceholder: () => {\\n      return {\\n        content: 'loading...',\\n        role: 'assistant',\\n      };\\n    },\\n    requestFallback: (_, { error }) => {\\n      if (error.name === 'AbortError') {\\n        return {\\n          content: 'Request is aborted',\\n          role: 'assistant',\\n        };\\n      }\\n      return {\\n        content: error?.toString(),\\n        role: 'assistant',\\n      };\\n    },\\n  });\\n\\n  const items = messages.map(({ message, id }) => ({\\n    key: id,\\n    ...message,\\n  }));\\n\\n  const role: BubbleListProps['role'] = {\\n    assistant: {\\n      placement: 'start',\\n    },\\n    user: { placement: 'end' },\\n  };\\n\\n  return (\\n    <Flex\\n      vertical\\n      justify=\\\"space-between\\\"\\n      style={{\\n        height: 400,\\n        padding: 16,\\n      }}\\n    >\\n      <Bubble.List role={role} items={items} />\\n      <Sender\\n        value={content}\\n        onChange={setContent}\\n        loading={requesting}\\n        onCancel={abort}\\n        onSubmit={(val) => {\\n          onRequest({\\n            messages: [{ role: 'user', content: val }],\\n          });\\n          setContent('');\\n        }}\\n      />\\n    </Flex>\\n  );\\n};\\n\\nexport default Demo;\\n\",\"paraId\":6,\"tocIndex\":3}];\n  "],"names":[],"mappings":"6PAEe,6CAAA,QADN,YACA,IAAM,EAAQ,CAAC,CAAC,MAAQ,4HAA4H,OAAS,CAAC,EAAE,CAAC,MAAQ,QAAQ,OAAS,CAAC,EAAE,CAAC,MAAQ,IAAI,OAAS,CAAC,EAAE,CAAC,MAAQ,0FAA0F,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,QAAQ,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,IAAI,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,0GAA0G,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,0BAA0B,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,IAAI,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,SAAS,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,0BAA0B,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,qDAAqD,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,gBAAgB,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,gBAAgB,OAAS,EAAE,SAAW,CAAC,EAAE,CAAC,MAAQ,4qGAA4qG,OAAS,EAAE,SAAW,CAAC,EAAE"}