(("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]=("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]||[]).push([["8255a3a9"],{"8255a3a9":function(e,n,t){"use strict";t.d(n,"__esModule",{value:!0}),t.d(n,"default",{enumerable:!0,get:function(){return p;}});var s=t("777fffbe"),r=t("dcc18016"),a=s._(t("9e95e7ac")),o=s._(t("80a4173a")),i=t("2ccdbe5e"),l=s._(t("d64cba85")),c=t("896e0d47"),d=t("aef44d3c"),p=function(){return(0,r.jsx)(i.DumiPage,{children:(0,r.jsx)(c.Suspense,{fallback:(0,r.jsx)(l.default,{}),children:(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)("div",{className:"markdown",children:[(0,r.jsxs)("p",{children:[d.texts[0].value,(0,r.jsx)(o.default,{to:"/sdks/introduce",sourceType:"Link",children:d.texts[1].value}),d.texts[2].value]}),(0,r.jsxs)("h2",{id:"integrate-with-x-sdk",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#integrate-with-x-sdk",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Integrate with X SDK"]}),(0,r.jsxs)("p",{children:[d.texts[3].value,(0,r.jsx)(o.default,{to:"/sdks/introduce",sourceType:"Link",children:d.texts[4].value}),d.texts[5].value]}),(0,r.jsxs)("h3",{id:"example",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#example",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Example"]})]}),(0,r.jsx)(i.DumiDemo,{demo:{id:"docs-react-model-use-openai-demo-model"},previewerProps:{title:"Integrate with X SDK",filename:"docs/x-sdk/demos/x-chat/model.tsx",pkgDependencyList:{"tbox-nodejs-sdk":"^0.0.13",openai:"^5.20.0","@antv/gpt-vis":"^0.4.1","@codesandbox/sandpack-react":"^2.19.8","@emotion/react":"^11.13.5","@emotion/server":"^11.11.0","@happy-dom/jest-environment":"^18.0.1","@ianvs/prettier-plugin-sort-imports":"^4.3.1","@microflash/rehype-figure":"^2.1.1","@npmcli/run-script":"^9.0.1","@octokit/rest":"^21.0.2","@prettier/sync":"^0.6.1","@qixian.cs/github-contributors-list":"^2.0.2","@rc-component/father-plugin":"^2.0.4","@rc-component/np":"^1.0.3","@rc-component/trigger":"^2.2.3","@stackblitz/sdk":"^1.11.0","@testing-library/dom":"^10.4.0","@testing-library/jest-dom":"^6.5.0","@testing-library/react":"^16.0.1","@testing-library/user-event":"^14.5.2","@types/adm-zip":"^0.5.5","@types/ali-oss":"^6.16.11","@types/cli-progress":"^3.11.6","@types/fs-extra":"^11.0.4","@types/gtag.js":"^0.0.20","@types/http-server":"^0.12.4","@types/inquirer":"^9.0.7","@types/isomorphic-fetch":"^0.0.39","@types/jest":"^30.0.0","@types/jest-axe":"^3.5.9","@types/jest-environment-puppeteer":"^5.0.6","@types/jest-image-snapshot":"^6.4.0","@types/jquery":"^3.5.30","@types/jsdom":"^27.0.0","@types/lodash":"^4.17.7","@types/minimist":"^1.2.5","@types/node":"^24.0.3","@types/ora":"^3.2.0","@types/pixelmatch":"^5.2.6","@types/pngjs":"^6.0.5","@types/prismjs":"^1.26.4","@types/progress":"^2.0.7","@types/qs":"^6.9.16","@types/react":"^19.0.2","@types/react-copy-to-clipboard":"^5.0.7","@types/react-dom":"^19.0.2","@types/react-highlight-words":"^0.20.0","@types/react-resizable":"^3.0.8","@types/semver":"^7.5.8","@types/spinnies":"^0.5.3","@types/tar":"^6.1.13","@types/throttle-debounce":"^5.0.2","@types/warning":"^3.0.3","@umijs/fabric":"^4.0.1","adm-zip":"^0.5.16","ali-oss":"^6.21.0",antd:"^6.0.0","antd-style":"^4.0.0-alpha.1","antd-token-previewer":"^3.0.0",axios:"^1.7.7",browserslist:"^4.23.3","browserslist-to-esbuild":"^2.1.1",chalk:"^5.4.1",cheerio:"^1.0.0","cli-progress":"^3.12.0","copy-to-clipboard":"^3.3.3","cross-env":"^7.0.3","cross-fetch":"^4.0.0",crypto:"^1.0.1",dayjs:"^1.11.13",dumi:"~2.4.21","dumi-plugin-color-chunk":"^2.1.0","esbuild-loader":"^4.2.2","fast-glob":"^3.3.2","fetch-jsonp":"^1.3.0","fs-extra":"^11.2.0",glob:"^11.0.0","happy-dom":"^20.0.10",html2sketch:"^1.0.2","http-server":"^14.1.1","identity-obj-proxy":"^3.0.0",immer:"^10.1.1",inquirer:"^12.1.0","is-ci":"^4.1.0","isomorphic-fetch":"^3.0.0",jest:"^30.2.0","jest-axe":"^10.0.0","jest-canvas-mock":"^2.5.2","jest-environment-node":"^30.0.0","jest-image-snapshot":"^6.5.1","jest-puppeteer":"^11.0.0",jquery:"^3.7.1",jsdom:"^26.0.0","jsonml-to-react-element":"^1.1.11","jsonml.js":"^0.1.0",lodash:"^4.17.21","lottie-web":"^5.12.2","lunar-typescript":"^1.7.5","lz-string":"^1.5.0",minimist:"^1.2.8",mockdate:"^3.0.5","node-fetch":"^3.3.2","node-notifier":"^10.0.1",open:"^10.1.0",ora:"^8.1.0",pixelmatch:"^7.1.0",pngjs:"^7.0.0","prettier-plugin-jsdoc":"^1.3.0","pretty-format":"^30.0.0",prismjs:"^1.29.0",puppeteer:"^24.0.0",qs:"^6.13.0","rc-drawer":"^8.0.0","rc-footer":"^0.6.8","rc-resize-observer":"^1.4.0","rc-virtual-list":"^3.14.5",react:"^19.0.0","react-copy-to-clipboard":"^5.1.0","react-dom":"^19.0.0","react-highlight-words":"^0.20.0","react-infinite-scroll-component":"^6.1.0","react-intersection-observer":"^10.0.0","react-intl":"^7.1.11","react-resizable":"^3.0.5","react-router-dom":"^7.0.1","react-sticky-box":"^2.0.5","regenerator-runtime":"^0.14.1","rehype-stringify":"^10.0.0",remark:"^15.0.1","remark-cli":"^12.0.1","remark-gfm":"^4.0.0","remark-lint":"^10.0.0","remark-lint-no-undefined-references":"^5.0.0","remark-preset-lint-recommended":"^7.0.0","remark-rehype":"^11.1.0","scroll-into-view-if-needed":"^3.1.0",semver:"^7.6.3",sharp:"^0.33.5","simple-git":"^3.26.0",spinnies:"^0.5.1",tar:"^7.4.3",tsx:"^4.19.1",typedoc:"^0.28.0",typescript:"~5.8.2","vanilla-jsoneditor":"^3.0.0","web-streams-polyfill":"^4.0.0",webpack:"^5.94.0","webpack-bundle-analyzer":"^5.0.1","@ant-design/colors":"^8.0.0","@ant-design/cssinjs":"^2.0.0","@ant-design/cssinjs-utils":"^2.0.0","@ant-design/fast-color":"^3.0.0","@ant-design/icons":"^6.0.0","@babel/runtime":"^7.25.6",classnames:"^2.5.1","rc-motion":"^2.9.2","rc-util":"^5.43.0"},pkgPeerDependencies:{antd:"^6.0.0",react:">=18.0.0","react-dom":">=18.0.0"},jsx:"import { SyncOutlined } from '@ant-design/icons';\nimport { Bubble, Sender } from '@ant-design/x';\nimport XMarkdown from '@ant-design/x-markdown';\nimport { OpenAIChatProvider, useXChat, XRequest } from '@ant-design/x-sdk';\nimport { Button, Flex, Tooltip } from 'antd';\nimport React from 'react';\n/**\n * \u{1F514} Please replace the BASE_URL, PATH, MODEL, API_KEY with your own values.\n */\nconst BASE_URL = 'https://api.x.ant.design/api/big_model_glm-4.5-flash';\n/**\n * \u{1F514} The MODEL is fixed in the current request, please replace it with your BASE_UR and MODEL\n */\nconst MODEL = 'THUDM/glm-4-9b-chat';\nconst role = {\n  assistant: {\n    placement: 'start',\n    contentRender(content) {\n      // Double '\\n' in a mark will causes markdown parse as a new paragraph, so we need to replace it with a single '\\n'\n      const newContent = content.replace('/\\n\\n/g', '<br/><br/>');\n      return <XMarkdown content={newContent} />;\n    },\n  },\n  user: {\n    placement: 'end',\n  },\n};\nconst App = () => {\n  const [content, setContent] = React.useState('');\n  const [provider] = React.useState(\n    new OpenAIChatProvider({\n      request: XRequest(BASE_URL, {\n        manual: true,\n        params: {\n          model: MODEL,\n          stream: true,\n        },\n      }),\n    }),\n  );\n  // Chat messages\n  const { onRequest, messages, setMessages, setMessage, isRequesting, abort, onReload } = useXChat({\n    provider,\n    requestFallback: (_, { error }) => {\n      if (error.name === 'AbortError') {\n        return {\n          content: 'Request is aborted',\n          role: 'assistant',\n        };\n      }\n      return {\n        content: error.message || 'Request failed, please try again!',\n        role: 'assistant',\n      };\n    },\n    requestPlaceholder: () => {\n      return {\n        content: 'Please wait...',\n        role: 'assistant',\n      };\n    },\n  });\n  const addUserMessage = () => {\n    setMessages([\n      ...messages,\n      {\n        id: Date.now(),\n        message: { role: 'user', content: 'Add a new user message' },\n        status: 'success',\n      },\n    ]);\n  };\n  const addAIMessage = () => {\n    setMessages([\n      ...messages,\n      {\n        id: Date.now(),\n        message: { role: 'assistant', content: 'Add a new AI response' },\n        status: 'success',\n      },\n    ]);\n  };\n  const addSystemMessage = () => {\n    setMessages([\n      ...messages,\n      {\n        id: Date.now(),\n        message: { role: 'system', content: 'Add a new system message' },\n        status: 'success',\n      },\n    ]);\n  };\n  const editLastMessage = () => {\n    const lastMessage = messages[messages.length - 1];\n    setMessage(lastMessage.id, {\n      message: { role: lastMessage.message.role, content: 'Edit a message' },\n    });\n  };\n  return (\n    <Flex vertical gap=\"middle\">\n      <Flex vertical gap=\"middle\">\n        <div>\n          Current status:{' '}\n          {isRequesting\n            ? 'Requesting'\n            : messages.length === 0\n              ? 'No messages yet, please enter a question and send'\n              : 'Q&A completed'}\n        </div>\n        <Flex align=\"center\" gap=\"middle\">\n          <Button disabled={!isRequesting} onClick={abort}>\n            abort\n          </Button>\n          <Button onClick={addUserMessage}>Add a user message</Button>\n          <Button onClick={addAIMessage}>Add an AI message</Button>\n          <Button onClick={addSystemMessage}>Add a system message</Button>\n          <Button disabled={!messages.length} onClick={editLastMessage}>\n            Edit the last message\n          </Button>\n        </Flex>\n      </Flex>\n\n      <Bubble.List\n        style={{ height: 500 }}\n        role={role}\n        items={messages.map(({ id, message, status }) => ({\n          key: id,\n          role: message.role,\n          status: status,\n          loading: status === 'loading',\n          content: message.content,\n          components:\n            message.role === 'assistant'\n              ? {\n                  footer: (\n                    <Tooltip title=\"Retry\">\n                      <Button\n                        size=\"small\"\n                        type=\"text\"\n                        icon={<SyncOutlined />}\n                        style={{ marginInlineEnd: 'auto' }}\n                        onClick={() =>\n                          onReload(id, {\n                            userAction: 'retry',\n                          })\n                        }\n                      />\n                    </Tooltip>\n                  ),\n                }\n              : {},\n        }))}\n      />\n      <Sender\n        loading={isRequesting}\n        value={content}\n        onCancel={() => {\n          abort();\n        }}\n        onChange={setContent}\n        onSubmit={nextContent => {\n          onRequest({\n            messages: [\n              {\n                role: 'user',\n                content: nextContent,\n              },\n            ],\n            frequency_penalty: 0,\n            max_tokens: 1024,\n            thinking: {\n              type: 'disabled',\n            },\n          });\n          setContent('');\n        }}\n      />\n    </Flex>\n  );\n};\nexport default App;\n",description:"<p>Access to cloud service platform,can send messages, process data, abort stream.</p>"}}),(0,r.jsxs)("div",{className:"markdown",children:[(0,r.jsxs)("h2",{id:"using-openai-node",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#using-openai-node",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Using openai-node"]}),(0,r.jsxs)("p",{children:[d.texts[6].value,(0,r.jsx)("code",{children:d.texts[7].value}),d.texts[8].value]}),(0,r.jsx)("blockquote",{children:(0,r.jsxs)("p",{children:[d.texts[9].value,(0,r.jsx)("code",{children:d.texts[10].value}),d.texts[11].value,(0,r.jsx)(o.default,{href:"https://github.com/openai/openai-node?tab=readme-ov-file#requirements",sourceType:"a",children:d.texts[12].value}),d.texts[13].value]})}),(0,r.jsx)(a.default,{lang:"tsx",children:d.texts[14].value}),(0,r.jsxs)("h3",{id:"example-1",children:[(0,r.jsx)(o.default,{"aria-hidden":"true",tabIndex:"-1",href:"#example-1",sourceType:"a",children:(0,r.jsx)("span",{className:"icon icon-link"})}),"Example"]})]}),(0,r.jsx)(i.DumiDemo,{demo:{id:"docs-react-model-use-openai-demo-openai-node"},previewerProps:{title:"Integrate openai",description:"<p>When using SDKs (such as <code>openai-node</code>, <code>@openrouter/ai-sdk-provider</code>) to request models or agents, you need to use the built-in Provider to handle data and customize the Request. Please refer to this example. <strong>Note</strong>: This example only demonstrates the logic for integrating openai using X SDK as a reference, and does not process model data. You need to fill in the correct apiKey for data debugging.</p>",filename:"docs/x-sdk/demos/x-chat/openai-node.tsx",pkgDependencyList:{"tbox-nodejs-sdk":"^0.0.13",openai:"^5.20.0","@antv/gpt-vis":"^0.4.1","@codesandbox/sandpack-react":"^2.19.8","@emotion/react":"^11.13.5","@emotion/server":"^11.11.0","@happy-dom/jest-environment":"^18.0.1","@ianvs/prettier-plugin-sort-imports":"^4.3.1","@microflash/rehype-figure":"^2.1.1","@npmcli/run-script":"^9.0.1","@octokit/rest":"^21.0.2","@prettier/sync":"^0.6.1","@qixian.cs/github-contributors-list":"^2.0.2","@rc-component/father-plugin":"^2.0.4","@rc-component/np":"^1.0.3","@rc-component/trigger":"^2.2.3","@stackblitz/sdk":"^1.11.0","@testing-library/dom":"^10.4.0","@testing-library/jest-dom":"^6.5.0","@testing-library/react":"^16.0.1","@testing-library/user-event":"^14.5.2","@types/adm-zip":"^0.5.5","@types/ali-oss":"^6.16.11","@types/cli-progress":"^3.11.6","@types/fs-extra":"^11.0.4","@types/gtag.js":"^0.0.20","@types/http-server":"^0.12.4","@types/inquirer":"^9.0.7","@types/isomorphic-fetch":"^0.0.39","@types/jest":"^30.0.0","@types/jest-axe":"^3.5.9","@types/jest-environment-puppeteer":"^5.0.6","@types/jest-image-snapshot":"^6.4.0","@types/jquery":"^3.5.30","@types/jsdom":"^27.0.0","@types/lodash":"^4.17.7","@types/minimist":"^1.2.5","@types/node":"^24.0.3","@types/ora":"^3.2.0","@types/pixelmatch":"^5.2.6","@types/pngjs":"^6.0.5","@types/prismjs":"^1.26.4","@types/progress":"^2.0.7","@types/qs":"^6.9.16","@types/react":"^19.0.2","@types/react-copy-to-clipboard":"^5.0.7","@types/react-dom":"^19.0.2","@types/react-highlight-words":"^0.20.0","@types/react-resizable":"^3.0.8","@types/semver":"^7.5.8","@types/spinnies":"^0.5.3","@types/tar":"^6.1.13","@types/throttle-debounce":"^5.0.2","@types/warning":"^3.0.3","@umijs/fabric":"^4.0.1","adm-zip":"^0.5.16","ali-oss":"^6.21.0",antd:"^6.0.0","antd-style":"^4.0.0-alpha.1","antd-token-previewer":"^3.0.0",axios:"^1.7.7",browserslist:"^4.23.3","browserslist-to-esbuild":"^2.1.1",chalk:"^5.4.1",cheerio:"^1.0.0","cli-progress":"^3.12.0","copy-to-clipboard":"^3.3.3","cross-env":"^7.0.3","cross-fetch":"^4.0.0",crypto:"^1.0.1",dayjs:"^1.11.13",dumi:"~2.4.21","dumi-plugin-color-chunk":"^2.1.0","esbuild-loader":"^4.2.2","fast-glob":"^3.3.2","fetch-jsonp":"^1.3.0","fs-extra":"^11.2.0",glob:"^11.0.0","happy-dom":"^20.0.10",html2sketch:"^1.0.2","http-server":"^14.1.1","identity-obj-proxy":"^3.0.0",immer:"^10.1.1",inquirer:"^12.1.0","is-ci":"^4.1.0","isomorphic-fetch":"^3.0.0",jest:"^30.2.0","jest-axe":"^10.0.0","jest-canvas-mock":"^2.5.2","jest-environment-node":"^30.0.0","jest-image-snapshot":"^6.5.1","jest-puppeteer":"^11.0.0",jquery:"^3.7.1",jsdom:"^26.0.0","jsonml-to-react-element":"^1.1.11","jsonml.js":"^0.1.0",lodash:"^4.17.21","lottie-web":"^5.12.2","lunar-typescript":"^1.7.5","lz-string":"^1.5.0",minimist:"^1.2.8",mockdate:"^3.0.5","node-fetch":"^3.3.2","node-notifier":"^10.0.1",open:"^10.1.0",ora:"^8.1.0",pixelmatch:"^7.1.0",pngjs:"^7.0.0","prettier-plugin-jsdoc":"^1.3.0","pretty-format":"^30.0.0",prismjs:"^1.29.0",puppeteer:"^24.0.0",qs:"^6.13.0","rc-drawer":"^8.0.0","rc-footer":"^0.6.8","rc-resize-observer":"^1.4.0","rc-virtual-list":"^3.14.5",react:"^19.0.0","react-copy-to-clipboard":"^5.1.0","react-dom":"^19.0.0","react-highlight-words":"^0.20.0","react-infinite-scroll-component":"^6.1.0","react-intersection-observer":"^10.0.0","react-intl":"^7.1.11","react-resizable":"^3.0.5","react-router-dom":"^7.0.1","react-sticky-box":"^2.0.5","regenerator-runtime":"^0.14.1","rehype-stringify":"^10.0.0",remark:"^15.0.1","remark-cli":"^12.0.1","remark-gfm":"^4.0.0","remark-lint":"^10.0.0","remark-lint-no-undefined-references":"^5.0.0","remark-preset-lint-recommended":"^7.0.0","remark-rehype":"^11.1.0","scroll-into-view-if-needed":"^3.1.0",semver:"^7.6.3",sharp:"^0.33.5","simple-git":"^3.26.0",spinnies:"^0.5.1",tar:"^7.4.3",tsx:"^4.19.1",typedoc:"^0.28.0",typescript:"~5.8.2","vanilla-jsoneditor":"^3.0.0","web-streams-polyfill":"^4.0.0",webpack:"^5.94.0","webpack-bundle-analyzer":"^5.0.1","@ant-design/colors":"^8.0.0","@ant-design/cssinjs":"^2.0.0","@ant-design/cssinjs-utils":"^2.0.0","@ant-design/fast-color":"^3.0.0","@ant-design/icons":"^6.0.0","@babel/runtime":"^7.25.6",classnames:"^2.5.1","rc-motion":"^2.9.2","rc-util":"^5.43.0"},pkgPeerDependencies:{antd:"^6.0.0",react:">=18.0.0","react-dom":">=18.0.0"},jsx:"var __awaiter =\n  (this && this.__awaiter) ||\n  function (thisArg, _arguments, P, generator) {\n    function adopt(value) {\n      return value instanceof P\n        ? value\n        : new P(function (resolve) {\n            resolve(value);\n          });\n    }\n    return new (P || (P = Promise))(function (resolve, reject) {\n      function fulfilled(value) {\n        try {\n          step(generator.next(value));\n        } catch (e) {\n          reject(e);\n        }\n      }\n      function rejected(value) {\n        try {\n          step(generator['throw'](value));\n        } catch (e) {\n          reject(e);\n        }\n      }\n      function step(result) {\n        result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n      }\n      step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n  };\nimport { Bubble, Sender } from '@ant-design/x';\nimport { AbstractXRequestClass, OpenAIChatProvider, useXChat } from '@ant-design/x-sdk';\nimport { Flex } from 'antd';\nimport OpenAI from 'openai';\nimport React, { useState } from 'react';\nclass OpenAiRequest extends AbstractXRequestClass {\n  constructor(baseURL, options) {\n    super(baseURL, options);\n    this._isTimeout = false;\n    this._isStreamTimeout = false;\n    this._isRequesting = false;\n    this.client = new OpenAI({\n      apiKey: 'OPENAI_API_KEY',\n      dangerouslyAllowBrowser: true,\n    });\n  }\n  get asyncHandler() {\n    return Promise.resolve();\n  }\n  get isTimeout() {\n    return this._isTimeout;\n  }\n  get isStreamTimeout() {\n    return this._isStreamTimeout;\n  }\n  get isRequesting() {\n    return this._isRequesting;\n  }\n  get manual() {\n    return true;\n  }\n  run(input) {\n    return __awaiter(this, void 0, void 0, function* () {\n      var _a, _b;\n      const { callbacks } = this.options;\n      try {\n        yield this.client.responses.create({\n          model: 'gpt-4o',\n          input:\n            ((_b =\n              (_a = input === null || input === void 0 ? void 0 : input.messages) === null ||\n              _a === void 0\n                ? void 0\n                : _a[0]) === null || _b === void 0\n              ? void 0\n              : _b.content) || '',\n          stream: true,\n        });\n        // \u8BF7\u57FA\u4E8E response \u5B9E\u73B0 \u6D41\u6570\u636E\u66F4\u65B0\u903B\u8F91\n        // Please implement stream data update logic based on response\n      } catch (error) {\n        callbacks === null || callbacks === void 0 ? void 0 : callbacks.onError(error);\n      }\n    });\n  }\n  abort() {\n    // \u8BF7\u57FA\u4E8Eopenai \u5B9E\u73B0 abort\n    // Please implement abort based on OpenAI\n  }\n}\nconst provider = new OpenAIChatProvider({\n  request: new OpenAiRequest('OPENAI', {}),\n});\nconst Demo = () => {\n  const [content, setContent] = useState('');\n  const { onRequest, messages, isRequesting, abort } = useXChat({\n    provider,\n    requestPlaceholder: () => {\n      return {\n        content: 'loading...',\n        role: 'assistant',\n      };\n    },\n    requestFallback: (_, { error }) => {\n      if (error.name === 'AbortError') {\n        return {\n          content: 'Request is aborted',\n          role: 'assistant',\n        };\n      }\n      return {\n        content: error === null || error === void 0 ? void 0 : error.toString(),\n        role: 'assistant',\n      };\n    },\n  });\n  const items = messages.map(({ message, id }) => Object.assign({ key: id }, message));\n  const role = {\n    assistant: {\n      placement: 'start',\n    },\n    user: { placement: 'end' },\n  };\n  return (\n    <Flex\n      vertical\n      gap={16}\n      justify=\"space-between\"\n      style={{\n        padding: 16,\n      }}\n    >\n      <Bubble.List style={{ height: 500 }} role={role} items={items} />\n      <Sender\n        value={content}\n        onChange={setContent}\n        loading={isRequesting}\n        onCancel={abort}\n        onSubmit={val => {\n          onRequest({\n            messages: [{ role: 'user', content: val }],\n          });\n          setContent('');\n        }}\n      />\n    </Flex>\n  );\n};\nexport default Demo;\n"}})]})})});};},aef44d3c:function(e,n,t){"use strict";t.d(n,"__esModule",{value:!0}),t.d(n,"texts",{enumerable:!0,get:function(){return s;}}),t("67d0a28d");let s=[{value:"This guide introduces how to integrate OpenAI model services into applications built with Ant Design X. For details, see ",paraId:0},{value:"X SDK",paraId:1},{value:".",paraId:0},{value:"Using URL to integrate Model is a basic capability provided by X SDK. For details, see ",paraId:2,tocIndex:0},{value:"X SDK",paraId:3,tocIndex:0},{value:".",paraId:2,tocIndex:0},{value:"Usually, openai-node is used in the node environment. If you use it in the browser, you need to enable ",paraId:4,tocIndex:3},{value:"dangerouslyAllowBrowser",paraId:4,tocIndex:3},{value:".",paraId:4,tocIndex:3},{value:"Note: ",paraId:5,tocIndex:3},{value:"dangerouslyAllowBrowser",paraId:5,tocIndex:3},{value:" has security risks. See the official openai-node ",paraId:5,tocIndex:3},{value:"documentation",paraId:5,tocIndex:3},{value:" for details.",paraId:5,tocIndex:3},{value:"import { Bubble, BubbleListProps, Sender } from '@ant-design/x';\nimport {\n  AbstractXRequestClass,\n  OpenAIChatProvider,\n  SSEFields,\n  useXChat,\n  XModelMessage,\n  XModelParams,\n  XRequestOptions,\n} from '@ant-design/x-sdk';\nimport { Flex } from 'antd';\nimport OpenAI from 'openai';\nimport React, { useState } from 'react';\n\ntype OutputType = Partial<Record<SSEFields, any>>;\ntype InputType = XModelParams;\n\nclass OpenAiRequest<\n  Input extends InputType = InputType,\n  Output extends OutputType = OutputType,\n> extends AbstractXRequestClass<Input, Output> {\n  client: any;\n  stream: OpenAI | undefined;\n\n  _isTimeout = false;\n  _isStreamTimeout = false;\n  _isRequesting = false;\n\n  constructor(baseURL: string, options: XRequestOptions<Input, Output>) {\n    super(baseURL, options);\n    this.client = new OpenAI({\n      apiKey: 'OPENAI_API_KEY',\n      dangerouslyAllowBrowser: true,\n    });\n  }\n  get asyncHandler(): Promise<any> {\n    return Promise.resolve();\n  }\n  get isTimeout(): boolean {\n    return this._isTimeout;\n  }\n  get isStreamTimeout(): boolean {\n    return this._isStreamTimeout;\n  }\n  get isRequesting(): boolean {\n    return this._isRequesting;\n  }\n  get manual(): boolean {\n    return true;\n  }\n  async run(input: Input): Promise<void> {\n    const { callbacks } = this.options;\n    try {\n      await this.client.responses.create({\n        model: 'gpt-4o',\n        input: input?.messages?.[0]?.content || '',\n        stream: true,\n      });\n\n      // Please implement stream data update logic based on response\n    } catch (error: any) {\n      callbacks?.onError(error);\n    }\n  }\n  abort(): void {\n    // Please implement abort based on OpenAI\n  }\n}\n\nconst provider = new OpenAIChatProvider<XModelMessage, InputType, OutputType>({\n  request: new OpenAiRequest('OPENAI', {}),\n});\n\nconst Demo: React.FC = () => {\n  const [content, setContent] = useState('');\n  const { onRequest, messages, requesting, abort } = useXChat({\n    provider,\n    requestPlaceholder: () => {\n      return {\n        content: 'loading...',\n        role: 'assistant',\n      };\n    },\n    requestFallback: (_, { error }) => {\n      if (error.name === 'AbortError') {\n        return {\n          content: 'Request is aborted',\n          role: 'assistant',\n        };\n      }\n      return {\n        content: error?.toString(),\n        role: 'assistant',\n      };\n    },\n  });\n\n  const items = messages.map(({ message, id }) => ({\n    key: id,\n    ...message,\n  }));\n\n  const role: BubbleListProps['role'] = {\n    assistant: {\n      placement: 'start',\n    },\n    user: { placement: 'end' },\n  };\n\n  return (\n    <Flex\n      vertical\n      justify=\"space-between\"\n      style={{\n        height: 400,\n        padding: 16,\n      }}\n    >\n      <Bubble.List role={role} items={items} />\n      <Sender\n        value={content}\n        onChange={setContent}\n        loading={requesting}\n        onCancel={abort}\n        onSubmit={(val) => {\n          onRequest({\n            messages: [{ role: 'user', content: val }],\n          });\n          setContent('');\n        }}\n      />\n    </Flex>\n  );\n};\n\nexport default Demo;\n",paraId:6,tocIndex:3}];}}]);
//# sourceMappingURL=8255a3a9-async.333a1a54.js.map